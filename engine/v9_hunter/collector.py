import requests
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
import re

class NewsCollector:
    def __init__(self):
        # Google News RSS URL (ê²€ìƒ‰ì–´ ê¸°ë°˜)
        self.base_url = "https://news.google.com/rss/search?q={query}&hl=en-US&gl=US&ceid=US:en"
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }

    def _clean_html(self, raw_html):
        cleanr = re.compile('<.*?>')
        cleantext = re.sub(cleanr, '', raw_html)
        return cleantext

    def get_news(self, symbol: str, lookback_days: int = 3) -> list:
        """
        íŠ¹ì • í‹°ì»¤ì˜ ìµœê·¼ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ë°˜í™˜
        """
        # ê²€ìƒ‰ì–´ ìƒì„± (í‹°ì»¤ + stock í‚¤ì›Œë“œ ì¡°í•©)
        query = f"{symbol} stock news"
        url = self.base_url.format(query=query)
        
        print(f"ğŸ“¡ [Collector] Fetching news for: {symbol}...")
        
        try:
            resp = requests.get(url, headers=self.headers, timeout=10)
            if resp.status_code != 200:
                print(f"âš ï¸ [Collector] Failed to fetch news: {resp.status_code}")
                return []
            
            # XML íŒŒì‹±
            root = ET.fromstring(resp.content)
            items = root.findall(".//item")
            
            news_list = []
            cutoff_date = datetime.now() - timedelta(days=lookback_days)
            
            for item in items[:5]: # ìƒìœ„ 5ê°œë§Œ (ì†ë„ ìµœì í™”)
                title = item.find("title").text if item.find("title") is not None else "No Title"
                link = item.find("link").text if item.find("link") is not None else ""
                pub_date_str = item.find("pubDate").text if item.find("pubDate") is not None else ""
                
                # ë‚ ì§œ íŒŒì‹± (ì˜ˆ: Mon, 01 Feb 2026 10:00:00 GMT)
                # íŒŒì‹± ì‹¤íŒ¨ì‹œ í˜„ì¬ ì‹œê°„ìœ¼ë¡œ ëŒ€ì²´í•˜ì—¬ ì—ëŸ¬ ë°©ì§€
                try:
                    pub_date = datetime.strptime(pub_date_str, "%a, %d %b %Y %H:%M:%S %Z")
                except:
                    pub_date = datetime.now()

                if pub_date >= cutoff_date:
                    news_list.append({
                        "source": "GoogleNews",
                        "title": title,
                        "link": link,
                        "published": pub_date.strftime("%Y-%m-%d"),
                        "snippet": title # RSSëŠ” ë³¸ë¬¸ì´ ì—†ìœ¼ë¯€ë¡œ ì œëª©ì„ snippetìœ¼ë¡œ í™œìš©
                    })
            
            print(f"   âœ… Found {len(news_list)} recent articles.")
            return news_list

        except Exception as e:
            print(f"âŒ [Collector] Error: {e}")
            return []

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    collector = NewsCollector()
    news = collector.get_news("TSLA", lookback_days=2)
    for n in news:
        print(f" - [{n['published']}] {n['title']}")
